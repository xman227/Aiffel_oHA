{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3204f5f7",
   "metadata": {},
   "source": [
    "# Project - how to use Scikit-Learn  \n",
    "\n",
    "## -Readme\n",
    "\n",
    "안녕하세요, 이번엔 Scikit-learn 라이브러리 및 모듈을 이용하고  \n",
    "자체 제공 데이터셋 (숫자 데이터, 와인 데이터, 유방암 데이터) 를 이용해  \n",
    "알고리즘 모델을 학습 및 평가해보는 시간을 가지려 합니다!\n",
    "\n",
    "Hello, I'm going to use the Scikit-learn library and modules.   \n",
    "Using datasets in sklearn(number data, wine data, breast cancer data),   \n",
    "We're going to take some time to learn and evaluate algorithmic models.   \n",
    "\n",
    "## -Contexts\n",
    "\n",
    "1. Digit data\n",
    " - load data\n",
    " - data preprocessing\n",
    " - fit & evaluate Algorithm\n",
    "    - 1 Decision Tree\n",
    "    - 2 Random Forest\n",
    "    - 3 SVM\n",
    "    - 4 SGD Classifier\n",
    "    - 5 Rogistic Regression\n",
    "    \n",
    "    \n",
    "2. Wine data\n",
    "\n",
    "3. Breast Cancer data\n",
    "\n",
    "## -rubric \n",
    "\n",
    "|평가문항|상세기준|\n",
    "|---|---|\n",
    "|데이터셋의 구성이 합리적으로 진행되었는가|feature와 label 선정을 위한 데이터 분석이 체계적으로 전개되었는지|\n",
    "|3가지 데이터셋에 각각 5가지 모델을 잘 적용시켰는가|모델학습 및 테스트가 정상적으로 이루어졌는지|\n",
    "|데이터셋에 따라 모델 평가지표를 적절히 선택했는가|평가지표 선택 및 이유 설명이 타당한지|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b97cce7",
   "metadata": {},
   "source": [
    "# 1. First_data : Digit\n",
    "\n",
    "아래의 코드는 다음과 같다.\n",
    "1. Digit data를 불러오기\n",
    "2. Feature Data 를 x 에 넣기\n",
    "3. Label Data 를 y에 넣기\n",
    "4. Target Names 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d41eb10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "digit_data = load_digits()\n",
    "\n",
    "digit_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b847b",
   "metadata": {},
   "source": [
    "보는 바와 같이 scikit-learn에서 제공하는 데이터는  \n",
    "딕셔너리처럼 키와 벨류 값을 꺼내 올 수가 있다.(엄밀히 딕셔너리는 아니다)  \n",
    "\n",
    "우리가 주요하게 보아야 할 데이터는 다음과 같다  \n",
    "data = 숫자 데이터의 이미지 값  \n",
    "target = 숫자데이터의 라벨링 값  \n",
    "feature_name = data 값에 대한 설명  \n",
    "targret_name = 라벨링 값에 대한 설명  \n",
    "DESCR = 종합적인 설명(descript)  \n",
    "\n",
    "타 자료도 이와 비슷한 형식으로 구성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e69da72",
   "metadata": {},
   "source": [
    "data와 target key가 보인다. 이를 x와 y 변수에 넣자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "034ddfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_x, digit_y =  digit_data['data'], digit_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b15f67c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "for i in (digit_x,digit_y):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd6cf7",
   "metadata": {},
   "source": [
    "x에는 64개(8x8 의 image_data) 의 feature 값이 1797개의 행으로 이루어져 있다.  \n",
    "y에는 1797 개의 라벨링 데이터가 들어있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30e662",
   "metadata": {},
   "source": [
    "image_data 의 분류 기준이 뭘까? Target_Name 에서 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d4163c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(digit_data['target_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeba233e",
   "metadata": {},
   "source": [
    "0~9 까지의 라벨링이 되어있음을 확인할 수 있다.  \n",
    "이는 Descript 에서도 찾아 볼 수 있는데, 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9762d582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digit_data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf7e23b",
   "metadata": {},
   "source": [
    "데이터에 대한 이해를 했으니, 본격적으로 전처리 후 모델학습을 시켜보자.\n",
    "\n",
    "##### 진행순서\n",
    "> 1. train 데이터와 test 데이터 분리하기  \n",
    "2. 적합한 모델 찾아 생성 후 학습시키기\n",
    "3. 예측하기\n",
    "4. 정확도 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badd40a1",
   "metadata": {},
   "source": [
    "## 1. 데이터 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22f625a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터 분리 모듈\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 알고리즘 모델 생성 모듈\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.linear_model import SGDClassifier # SGD Classifier\n",
    "from sklearn.linear_model import LogisticRegression # Logistic Regression\n",
    "\n",
    "#모델 평가 모듈 (위 모델과 대응)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# 데이터 분리하기\n",
    "train_x, test_x, train_y, test_y = train_test_split(digit_x,digit_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b21d26",
   "metadata": {},
   "source": [
    "## 2 적합한 모델 찾아 진행  \n",
    "\n",
    "### 2-1 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ed03e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91        33\n",
      "           1       0.84      0.75      0.79        28\n",
      "           2       0.77      0.73      0.75        33\n",
      "           3       0.81      0.88      0.85        34\n",
      "           4       0.77      0.87      0.82        46\n",
      "           5       0.91      0.83      0.87        47\n",
      "           6       0.89      0.94      0.92        35\n",
      "           7       0.83      0.88      0.86        34\n",
      "           8       0.76      0.73      0.75        30\n",
      "           9       0.85      0.82      0.84        40\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.84      0.83      0.83       360\n",
      "weighted avg       0.84      0.84      0.84       360\n",
      "\n",
      "accuracy =  0.8361111111111111\n"
     ]
    }
   ],
   "source": [
    "Tree_model = DecisionTreeClassifier()\n",
    "Tree_model.fit(train_x, train_y)\n",
    "\n",
    "Tree_y_pred = Tree_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, Tree_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, Tree_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac944fc",
   "metadata": {},
   "source": [
    "### 2-2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17984ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        33\n",
      "           1       0.93      1.00      0.97        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.98      1.00      0.99        46\n",
      "           5       0.98      0.98      0.98        47\n",
      "           6       0.97      0.97      0.97        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      0.93      0.97        30\n",
      "           9       0.97      0.97      0.97        40\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "accuracy =  0.9805555555555555\n"
     ]
    }
   ],
   "source": [
    "Forest_model = RandomForestClassifier()\n",
    "Forest_model.fit(train_x, train_y)\n",
    "\n",
    "Forest_y_pred = Forest_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, Forest_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, Forest_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0034516",
   "metadata": {},
   "source": [
    "### 2-3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "088a7770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.98      0.98      0.98        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      0.97      0.98        30\n",
      "           9       0.95      0.95      0.95        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "accuracy =  0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "SVM_model = SVC()\n",
    "SVM_model.fit(train_x, train_y)\n",
    "\n",
    "SVM_y_pred = SVM_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, SVM_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, SVM_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be61f2d",
   "metadata": {},
   "source": [
    "### 2-4 SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd658603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        33\n",
      "           1       0.88      1.00      0.93        28\n",
      "           2       0.97      0.97      0.97        33\n",
      "           3       0.92      0.97      0.94        34\n",
      "           4       1.00      0.96      0.98        46\n",
      "           5       0.83      0.96      0.89        47\n",
      "           6       0.92      0.97      0.94        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       0.93      0.87      0.90        30\n",
      "           9       1.00      0.75      0.86        40\n",
      "\n",
      "    accuracy                           0.94       360\n",
      "   macro avg       0.94      0.94      0.94       360\n",
      "weighted avg       0.94      0.94      0.94       360\n",
      "\n",
      "accuracy =  0.9361111111111111\n"
     ]
    }
   ],
   "source": [
    "SGD_model = SGDClassifier()\n",
    "SGD_model.fit(train_x, train_y)\n",
    "\n",
    "SGD_y_pred = SGD_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, SGD_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, SGD_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e650d2c",
   "metadata": {},
   "source": [
    "### 2-5 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b003ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       0.97      1.00      0.98        28\n",
      "           2       0.97      1.00      0.99        33\n",
      "           3       0.97      0.97      0.97        34\n",
      "           4       1.00      0.98      0.99        46\n",
      "           5       0.92      0.94      0.93        47\n",
      "           6       0.97      0.97      0.97        35\n",
      "           7       1.00      0.97      0.99        34\n",
      "           8       0.97      0.97      0.97        30\n",
      "           9       0.97      0.95      0.96        40\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "accuracy =  0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "Log_model = LogisticRegression(max_iter=5000)\n",
    "Log_model.fit(train_x, train_y)\n",
    "\n",
    "Log_y_pred = Log_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, Log_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, Log_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e994343",
   "metadata": {},
   "source": [
    "## 3 성능평가지표 선정 및 이유\n",
    "적합한 모델을 선정 및 평가하기 위해서는 **알고리즘과 측정지표**에 대한 이해를 필요로 한다.  \n",
    "\n",
    "### About Algorithm\n",
    "\n",
    "현재 우리가 사용한 알고리즘의 종류는 아래와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396072d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. DecisionTreeClassifier\n",
    "2. RandomForestClassifier\n",
    "3. SVC # SVM\n",
    "4. SGD Classifier\n",
    "5. LogisticRegression\n",
    "\n",
    "다음에 sklearn 에서 제공하는 알고리즘 사용 가이드 이미지가 있다.\n",
    "<img src=\"./img/sklearn_guide.PNG\" width=\"600px\" height=\"500px\"></img>\n",
    "\n",
    "참고 : [sklearn algorithm site](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77555e0d",
   "metadata": {},
   "source": [
    "이렇게 하니 잘 안보이므로 내가 친절히 설명해주도록 하겠다.\n",
    "\n",
    "우선 우리가 진행하는 데이터는 모두 라벨링이 되어있는 지도학습이다. \n",
    "\n",
    "1. DecisionTreeClassifier \n",
    ">  데이터를 분석해 이들 사이에 존재하는 패턴을 규칙의 연속으로 나타내어 분류하는 방법  \n",
    "  가장 기본적인 방법이다. 다만 결정경계(desicion boundary)가 데이터 축에 수직이어서 특정 데이터에만 잘 작동하는 단점이 있다.\n",
    "2. RandomForestClassifier\n",
    "> 라벨링이 있고 샘플의 수가 10만개보다 적고 텍스트가 아닌 경우  \n",
    "  **Desicion Tree 의 단점을 극복하기 위해** n개의 Decision Tree로 나온 결정들의 비율로 정답을 추론하는 방식  \n",
    "\n",
    "3. SVC # SVM\n",
    "> 라벨링이 있고 샘플의 수가 10만개보다 적고 텍스트가 아닌 경우  \n",
    "  Support Vector 와 Hyperplane(초평면) 을 이용하여 분류를 수행한다. **주로 2개의 클래스가 존재할 때 사용**한다.  \n",
    "  \n",
    "4. SGD Classifier\n",
    "> 라벨링이 있고 샘플의 수(train_x의 행 값)가 10만개가 넘을 경우   \n",
    "  Stochastic Gradient Descent Classifier 확률적 경사하강법 이라고 불린다.  \n",
    "  배치 크기가 1인 경사하강법 알고리즘으로, 데이터 세트에서 무작위로 균일하게 선택한 하나의 예를 의존하여   \n",
    "  각 단계의 예측 경사를 계산한다.  \n",
    "  이는 보통 **거대한 샘플에서 간단한 확률적 분포를 이용해 간단히 결과를 예측**하고 싶을 때 사용한다.\n",
    "  \n",
    "5. LogisticRegression\n",
    "> 이름은 회귀지만 실제로는 분류를 사용한다.  \n",
    "  가장 널리 알려진 선형 분류 알고리즘이다.   \n",
    "  소프트맥스 (Softmax) 함수를 사용한 다중 클래스 분류 알고리즘이다. 이러한 로지스틱 회귀를 Softmax regression 이라고도 한다.  \n",
    "  클래스가 n개일 때, N차원의 벡터가 각 클래스의 정답일 확률을 표현하도록 정규화해주는 함수를 Softmax 함수라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33dd19",
   "metadata": {},
   "source": [
    "이에 따른 분류기준은 sklearn 의 matrics 페이지에서 찾을 수 있다.\n",
    "\n",
    "참고 : [sklearn.matrix](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed47e62",
   "metadata": {},
   "source": [
    "### About Report\n",
    "\n",
    "sykit learn 은 약 15개의 측정 지표 메서드를 가지고 있다. 그 중 가장 대표적으로 사용되는 3개의 지표는 다음과 같다.\n",
    "\n",
    "**1. accuracy - Precision, Recall**\n",
    "\n",
    "classification_report() 메서드를 사용하면 전체적인 accuracy 값과 다음의 구체적인 지표를 알 수가 있다,  \n",
    "\n",
    "**Precision(정밀도), Recall(재현율; sensitivity), F1 score** \n",
    " \n",
    "우리는 precision 과 Recall 의 중요도에 따라 다른 정확도를 비교할 필요가 있다.  \n",
    "precision 는 FP (가짜양성, 아닌데 맞다고 한 비율) 이 낮을수록 높다.   \n",
    "스팸문자같은건 스팸이 아닌걸 스팸이라 하면 문제가 크니까 이런거 precision 이 높아야 한다.  \n",
    "\n",
    "recall 는 FN (가짜음성, 맞는데 아니라고 한 비율) 이 낮을수록 좋다.  \n",
    "암 같은거, 빨리 발견해야 잡는데 아니라고 하면 문제가 크니까 이런거 recall 이 높아야 한다.  \n",
    "\n",
    "**2. top - K accuracy**  \n",
    "데이터셋에서 가장 높은 확률이 나온 K개의 자료를 일반화하여 계산해준다.\n",
    "\n",
    "**3. balanced accuracy**  \n",
    "데이터 셋 라벨의 불균형성을 고려해 계산해준다.\n",
    "데이터 불균형성이 높을수록 정확도가 떨어지게 만들어준다.\n",
    "\n",
    "---\n",
    "\n",
    "측정지표를 선정하기 위해서는  \n",
    "알고리즘의 사용 의도를 알아야 한다.\n",
    "\n",
    "1. Digit data\n",
    "알고리즘을 통해 숫자 이미지를 보고 어떤 수를 의미하는지를 판별하고자 했다.  \n",
    "우리가 직접 적은 숫자 그림을 보고 판별하는 알고리즘이기 때문에 다른 숫자와 혼동해서는 안된다.  \n",
    "때문에 FP FN 모두 중요하다.  \n",
    "\n",
    "2. Wine data\n",
    "와인의 각 특징을 입력하면 어떤 종류의 와인인지 구별하고자 했다.  \n",
    "이 또한 다른 와인들과 섞이면 안되기 때문에 FP FN 모두 중요하다.  \n",
    "\n",
    "\n",
    "3. Breast Cancer data\n",
    "환자의 데이터를 통해 유방암이 양성인지(걸렸는지) 음성인지를 판별하고자 했다.  \n",
    "구별 자체도 중요하지만 상대적으로  FP 보다는 FN 이 적게 나오도록 해야만 한다.  \n",
    "다시 말해서, 유방암 환자인데 유방암 환자가 아니라고 말하는 비율을 최대한 줄여야만 한다.  \n",
    "\n",
    "유방암이 아닌데 유방암이라 하는 것은 돌이킬 수 있지만, 그 반대의 경우  \n",
    "질병을 늦게 발견하게 된다면 돌이킬 수 없는 결과를 초래하기 때문이다.  \n",
    "\n",
    "그래서 recall 값이 중요해진다.  \n",
    "\n",
    "\n",
    "---\n",
    "다음의 이해를 바탕으로,\n",
    "\n",
    "digit 데이터는 \n",
    "\n",
    "약 1800개의 샘플로 이루어져 있는 이미지 데이터를 10개의 클래스로 나누어 분류하고 있으므로\n",
    "\n",
    "Decision Tree , Randomforest, Rogistic Regression 적합한 모델이고,  \n",
    "데이터의 특성 상 accuracy로 판단해야 한다고 생각한다.\n",
    "\n",
    "각각 0.84, 0.98, 0.97 이 나왔고 상당히 높은 수치이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6840b3d0",
   "metadata": {},
   "source": [
    "# Second_Data : Wine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d44a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "\n",
    "wine_data = load_wine()\n",
    "\n",
    "wine_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9a3356",
   "metadata": {},
   "source": [
    "data 와 target 을 x와 y 변수에 넣자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebbbbe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_x, wine_y =  wine_data['data'], wine_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a98552b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "(178,)\n"
     ]
    }
   ],
   "source": [
    "for i in (wine_x, wine_y):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab850bf",
   "metadata": {},
   "source": [
    "x에는 13개의 feature 값이 178개의 행으로 이루어져 있다.\n",
    "y에는 178 개의 라벨링 데이터가 들어있다.\n",
    "\n",
    "13개의 Feature_name이 뭘까? Target_Name 에서 알 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b812dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "print(wine_data['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d007dd7",
   "metadata": {},
   "source": [
    "위와 같이 와인 관련 13가지의 항목을 기록한 하나의 와인 값이 총 178개가 있음을 알 수 있다.  \n",
    "이는 DESCR을 통해서도 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1f73578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine_data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74e2580",
   "metadata": {},
   "source": [
    "## 1. 데이터 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ebced41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(digit_x,digit_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c00de9",
   "metadata": {},
   "source": [
    "## 2. 적합한 모델 찾아 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27316950",
   "metadata": {},
   "source": [
    "### 2-1 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02c05249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92        33\n",
      "           1       0.92      0.79      0.85        28\n",
      "           2       0.83      0.76      0.79        33\n",
      "           3       0.74      0.91      0.82        34\n",
      "           4       0.82      0.89      0.85        46\n",
      "           5       0.91      0.89      0.90        47\n",
      "           6       0.83      1.00      0.91        35\n",
      "           7       0.91      0.88      0.90        34\n",
      "           8       0.81      0.70      0.75        30\n",
      "           9       0.89      0.82      0.86        40\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.85      0.85       360\n",
      "weighted avg       0.86      0.86      0.86       360\n",
      "\n",
      "accuracy =  0.8583333333333333\n"
     ]
    }
   ],
   "source": [
    "Tree_model = DecisionTreeClassifier()\n",
    "Tree_model.fit(train_x, train_y)\n",
    "\n",
    "Tree_y_pred = Tree_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, Tree_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, Tree_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e53070",
   "metadata": {},
   "source": [
    "### 2-2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f70d1ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        33\n",
      "           1       0.93      1.00      0.97        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      0.97      0.99        34\n",
      "           4       0.98      1.00      0.99        46\n",
      "           5       0.94      0.96      0.95        47\n",
      "           6       0.97      0.97      0.97        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      0.93      0.97        30\n",
      "           9       0.95      0.95      0.95        40\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "accuracy =  0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "Forest_model = RandomForestClassifier()\n",
    "Forest_model.fit(train_x, train_y)\n",
    "\n",
    "Forest_y_pred = Forest_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, Forest_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, Forest_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384cbae2",
   "metadata": {},
   "source": [
    "### 2-3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4a7b871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.98      0.98      0.98        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      0.97      0.98        30\n",
      "           9       0.95      0.95      0.95        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "accuracy =  0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "SVM_model = SVC()\n",
    "SVM_model.fit(train_x, train_y)\n",
    "\n",
    "SVM_y_pred = SVM_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, SVM_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, SVM_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beda374",
   "metadata": {},
   "source": [
    "### 2-4 SGD Classifirer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aca1c1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        33\n",
      "           1       1.00      0.79      0.88        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      0.97      0.99        34\n",
      "           4       0.98      1.00      0.99        46\n",
      "           5       0.94      0.98      0.96        47\n",
      "           6       1.00      0.97      0.99        35\n",
      "           7       1.00      0.97      0.99        34\n",
      "           8       0.72      0.97      0.83        30\n",
      "           9       0.97      0.90      0.94        40\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.95      0.95       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n",
      "accuracy =  0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "SGD_model = SGDClassifier()\n",
    "SGD_model.fit(train_x, train_y)\n",
    "\n",
    "SGD_y_pred = SGD_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, SGD_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, SGD_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9869aa",
   "metadata": {},
   "source": [
    "### 2-5 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0544a263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       0.97      1.00      0.98        28\n",
      "           2       0.97      1.00      0.99        33\n",
      "           3       0.97      0.97      0.97        34\n",
      "           4       1.00      0.98      0.99        46\n",
      "           5       0.92      0.94      0.93        47\n",
      "           6       0.97      0.97      0.97        35\n",
      "           7       1.00      0.97      0.99        34\n",
      "           8       0.97      0.97      0.97        30\n",
      "           9       0.97      0.95      0.96        40\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "accuracy =  0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "Log_model = LogisticRegression(max_iter=5000)\n",
    "Log_model.fit(train_x, train_y)\n",
    "\n",
    "Log_y_pred = Log_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, Log_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, Log_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee4ac4",
   "metadata": {},
   "source": [
    "## 3 성능 평가지표 선정 및 이유\n",
    "\n",
    "wine 데이터는 \n",
    "\n",
    "약 180개의 샘플로 이루어져 있는 와인 특성 데이터를 3개의 클래스로 나누어 분류하고 있으므로\n",
    "\n",
    "Decision Tree , Randomforest, Rogistic Regression 적합한 모델이고,  \n",
    "데이터의 특성 상 accuracy로 판단해야 한다고 생각한다.\n",
    "\n",
    "각각 0.86, 0.97, 0.97 이 나왔고 양호하다고 생각한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f41230f",
   "metadata": {},
   "source": [
    "# Third_Data : Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f37c7752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "\n",
    "breast_cancer_data = load_breast_cancer()\n",
    "\n",
    "breast_cancer_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef86fc",
   "metadata": {},
   "source": [
    "data 와 target 을 x와 y변수에 넣자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8411f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_x, breast_cancer_y =  breast_cancer_data['data'], breast_cancer_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7267e07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "for i in (breast_cancer_x, breast_cancer_y):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6b26ab",
   "metadata": {},
   "source": [
    "유방암 데이터는 30개의 특성을 가진 하나의 자료가 579개의 행으로 이루어져 있다. 그러면 30개의 특성은 어떤 것들이 있을까?   \n",
    "feature_name을 알아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47806c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_data['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49502527",
   "metadata": {},
   "source": [
    "전문용어인지 그냥 영어로만 보니 무슨 특성을 가진 것인지 알기가 어렵다. DESCR 키를 불러와 전체적인 설명을 읽어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "866870bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(breast_cancer_data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866d2c7",
   "metadata": {},
   "source": [
    "위의 내용을 보면\n",
    "radius 는 암으로 추정되는 것의 반지름  \n",
    "texture 는 회색 물체 값의 표준편차 등  \n",
    "feature 속성 들에 대한 값을 확인해 볼 수가 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3d7849",
   "metadata": {},
   "source": [
    "## 1. 데이터 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "202457c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(breast_cancer_x,breast_cancer_y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4492756d",
   "metadata": {},
   "source": [
    "## 2. 적합한 모델 찾아 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b87f66",
   "metadata": {},
   "source": [
    "### 2-1 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b046d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        44\n",
      "           1       0.93      0.96      0.94        70\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "accuracy =  0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "Tree_model = DecisionTreeClassifier()\n",
    "Tree_model.fit(train_x, train_y)\n",
    "\n",
    "Tree_y_pred = Tree_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, Tree_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, Tree_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e640946",
   "metadata": {},
   "source": [
    "### 2-2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c31de0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93        44\n",
      "           1       0.93      0.99      0.96        70\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "accuracy =  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "Forest_model = RandomForestClassifier()\n",
    "Forest_model.fit(train_x, train_y)\n",
    "\n",
    "Forest_y_pred = Forest_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, Forest_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, Forest_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3225de3",
   "metadata": {},
   "source": [
    "### 2-3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98fa7455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.77      0.86        44\n",
      "           1       0.87      0.99      0.93        70\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.92      0.88      0.89       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "accuracy =  0.9035087719298246\n"
     ]
    }
   ],
   "source": [
    "SVM_model = SVC()\n",
    "SVM_model.fit(train_x, train_y)\n",
    "\n",
    "SVM_y_pred = SVM_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, SVM_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, SVM_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8cd7db",
   "metadata": {},
   "source": [
    "### 2-4 SGD Classifirer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb4e67cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.77      0.86        44\n",
      "           1       0.87      0.99      0.93        70\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.92      0.88      0.89       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "accuracy =  0.9035087719298246\n"
     ]
    }
   ],
   "source": [
    "SGD_model = SGDClassifier()\n",
    "SGD_model.fit(train_x, train_y)\n",
    "\n",
    "SGD_y_pred = SGD_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, SGD_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, SGD_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8aa625",
   "metadata": {},
   "source": [
    "### 2-5 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9368f3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86        44\n",
      "           1       0.90      0.93      0.92        70\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.88      0.89       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "accuracy =  0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "Log_model = LogisticRegression(max_iter=3000)\n",
    "Log_model.fit(train_x, train_y)\n",
    "\n",
    "Log_y_pred = Log_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, Log_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, Log_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6707283d",
   "metadata": {},
   "source": [
    "## 성능 평가지표 선정 및 이유\n",
    "\n",
    "breast cancer 데이터는 \n",
    "\n",
    "약 600명의 환자 데이터를 2개의 클래스로 나누어 분류하고 있으므로\n",
    "\n",
    "Decision Tree , Randomforest, Support Vector Machin 이 적합한 모델이고,  \n",
    "데이터의 특성 상 악성 라벨인 0 의 recall 로 판단해야 한다고 생각한다.  \n",
    "(0 = 악성 유방암, 1 = 초기 유방암)\n",
    "\n",
    "\n",
    "각각 0.89, 0.89, 0.77 이 나왔다. SVM 은 미흡한 수치가 나왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b038387",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995da16a",
   "metadata": {},
   "source": [
    "* **print()메서드의 작동방식에 한걸음 이해**\n",
    "\n",
    "여기서 단순한 호출(return) 과 print의 차이를 알게 될 줄은 몰랐다.\n",
    "\n",
    "단순히 DESCR 을 호출할 경우는 사람이 읽기에 쉽지 않다. 그리고 정규식 표현이 되지 않은 row형태로 출력된다.\n",
    "예를 들어 \\n 은 줄바꿈을을 의미하는 수식인데, 단순 return은 이러한 것을 표현식으로 인지하지 못하고 그냥 출력한다.\n",
    "하지만 print() 메서드를 쓰면 그런 수식들을 감안해 사람이 읽기 쉽게 호출해주었다.\n",
    "\n",
    "기본기의 중요성을 꺠닫는 순간이었다.\n",
    "\n",
    "\n",
    "* **각 알고리즘에 대한 원리 이해 부족**\n",
    "\n",
    "세 데이터 모두 알고리즘에 따라 다른 정확도가 나온다.  \n",
    "그러면 단순히 가장 높은 정확도를 보이는 모델이 가장 좋은 모델일까?  \n",
    "\n",
    "난 그렇게 생각하지 않는다.  \n",
    "\n",
    "5개의 알고리즘은 저마다 학습방법이 다르다.  \n",
    "때문에 각 학습 유형을 이해하고 그 데이터에 가장 적합한 알고리즘을 찾아 학습시키는 것이  \n",
    "정확도의 정확도를 가장 높이는 방법이라고 생각한다.\n",
    "\n",
    "말한 바와 같이 각 알고리즘의 원리를 이해해야 하지만,   \n",
    "아직 견문이 부족한지라 그 원리는 아직 잘 모르겠다.  \n",
    "\n",
    "허나 다행히도 scikit learn 에서 제공하는 guide 에 따라 \n",
    "각 데이터 특성에 맞는 모델을 선정했다.\n",
    "\n",
    "이렇게 하면 표면적으로는 어느정도 좋은 결과를 보이겠지만,\n",
    "분명 한계가 있을 것이다.\n",
    "\n",
    "특히 Logistic Regression 에서 그 문제가 드러났다.\n",
    "배운대로 기존코드를 넣었을때 물론 작동은 했지만,  \n",
    "scikit-learn 홈페이지 내부에서 자체적으로 warning이  출력되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a706c4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90        44\n",
      "           1       0.93      0.94      0.94        70\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "accuracy =  0.9210526315789473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "Log_model = LogisticRegression()\n",
    "Log_model.fit(train_x, train_y)\n",
    "\n",
    "Log_y_pred = Log_model.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y, Log_y_pred))\n",
    "print(\"accuracy = \", accuracy_score(test_y, Log_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69b46b",
   "metadata": {},
   "source": [
    "이 경고문이 무슨 의미를 가지고 있는지,\n",
    "그리고 경고문이 뜨지 않기 위해서는 어떻게 해야 하는지 전문가에게 묻거나 검색을 하여 방법을 찾았다.  \n",
    "\n",
    "[stack over flow](https://stackoverflow.com/questions/62658215/convergencewarning-lbfgs-failed-to-converge-status-1-stop-total-no-of-iter) 에서는 각지의 프로그래머들이 오류를 해결하는 커뮤니티 사이트이다. 이 사이트에서 이 경고문에 대해 설명하는 글이 있다.\n",
    "\n",
    "경고문 첫 문장을 보면 ConvergenceWarning: lbfgs failed to converge  이라고 되어 있다.  \n",
    "(수렴오류 : Ibfgs 는 수렴에 실패했습니다.  )\n",
    "\n",
    "Ibfgs 는 Limited-memoy Brouden-Fletcher-Goldfarb-Shanno Algorithm 의 약자로,  \n",
    "scikit learn 에서 제공하는 알고리즘의 하나다.\n",
    "\n",
    "이 알고리즘이 정상적으로 수렴하기 위해서는 로지스틱 회귀 메서드의 키워드 인자인 max_iter 의 값을 크게 설정해주면 된다고  \n",
    "설명되어 있었다. \n",
    "\n",
    "덕분에 경고를 해결하긴 했지만\n",
    "\n",
    "Ibfgs 라는 solver Algorithm 이 어떤 방식으로 동작하는 것인지  \n",
    "( gradients approximation 을 저장한다고 한다 )  \n",
    "\n",
    "max_iter 가 정확하게 무엇을 반복시키는 것인지  \n",
    "\n",
    "왜 처음부터 반복값을 크게 정하지 않았는지, 의문은 더 늘었다.\n",
    "\n",
    "바로 궁금증을 해결하고 싶지만, 알고리즘은 기본이 없는 상태에선 파도 파도 모르는 것만 나오는 것을 경험했다.  \n",
    "그래서 순방향 신경망부터 차례대로 공부해보려고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aee959",
   "metadata": {},
   "source": [
    "다음에는 아래의 알고리즘에 대한 질문을 스스로 답할 수 있도록 하고 싶다.\n",
    "\n",
    "1. DecisionTreeClassifier \n",
    ">  결정경계(desicion boundary)란?  \n",
    "   오버피팅과 가지치기에 대해 설명한다면?\n",
    "   \n",
    "3. SVC # SVM\n",
    "> Support Vector 와 Hyperplane(초평면)이 무엇인가?\n",
    "\n",
    "4. SGD Classifier\n",
    "> Stochastic Gradient Descent Classifier 확률적 경사하강법이 무엇인지?\n",
    "  예측경사와 배치 간의 관계는?\n",
    "  \n",
    "5. LogisticRegression\n",
    "> 소프트맥스 (Softmax) 함수눈 무엇인지?\n",
    "  로지스틱 회귀의 오차는 어떻게 구하는지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa27d014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
