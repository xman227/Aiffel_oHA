{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ff5473",
   "metadata": {},
   "source": [
    "# 인공지능 가위바위보 준비  \n",
    "- 데이터준비  \n",
    "- 딥러닝 네트워크 설계  \n",
    "- 학습  \n",
    "- 테스트(평가)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d81288",
   "metadata": {},
   "source": [
    "## 1. MNIST 숫자 손글씨 Dataset 불러오기   \n",
    "- Tensorflow 의 표준 API 인 tf.keras 의 Sequential API 를 중심으로\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52600d19",
   "metadata": {},
   "source": [
    "[여기](http://yann.lecun.com/exdb/mnist/) 에는 MNIST 교수님이  \n",
    "직접 만드신 손글씨 사진과 그에 맞는 데이터가 있다.\n",
    "\n",
    "데이터셋은 500명 사용자가 작성한 70,000장의 손글씨 사진이 있다.  \n",
    "(train 60000, test 10000)\n",
    "\n",
    "train 데이터와 test 데이터가 있는데  \n",
    "우리는 train을 가지고 알고리즘을 만든 다음에  \n",
    "test로 성능 테스트를 하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7350ce02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "print(tf.__version__)   # Tensorflow의 버전을 출력\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "# MNIST 데이터를 로드. 다운로드하지 않았다면 다운로드까지 자동으로 진행됩니다. \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   \n",
    "\n",
    "print(len(x_train))  # x_train 배열의 크기를 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713871bd",
   "metadata": {},
   "source": [
    "우리가 불러온 학습용 데이터 개수 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee961be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facc966e",
   "metadata": {},
   "source": [
    "6000개의 사진이 28x28 의 크기로 있다.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1b308d",
   "metadata": {},
   "source": [
    "여기서 잠깐\n",
    "---\n",
    "* Train set : 모델 학습 용 dataset  \n",
    "* Validation set : 학습이 완료된 모델을 검증하기 위한 dataset  \n",
    "* Test set : 학습도 검증도 완료된 모델의 성능 평가를 위한 dataset\n",
    "\n",
    "데이터 셋을 모은 다음 Train 6: Validation 2 : Test 2 의 비율로 나눈다.  \n",
    "(Validation 할만큼 양이 많지 않으면 Train에 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5987f06",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc36d53",
   "metadata": {},
   "source": [
    "인공지능 모델을 훈련/사용 할 때 , 일반적으로 입력을 0~1사이의 값으로 정규화 시켜 사용한다.\n",
    "\n",
    "MNIST 이미지 데이터는 각 픽셀의 값이 0 ~ 255 의 범위 내에 있으므로 데이터를 255.0 으로 나누어 주면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3f8126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소값: 0.0  최대값: 1.0\n"
     ]
    }
   ],
   "source": [
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "print('최소값:',np.min(x_train_norm), ' 최대값:',np.max(x_train_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60dc7c7",
   "metadata": {},
   "source": [
    "> 255로 나누어 0~1사이의 값을 만든 모습이다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fa6d06",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f894c",
   "metadata": {},
   "source": [
    "딥러닝 네트워크 설계는  \n",
    "텐서플로우 케라스 (tf.keras) 에서 Sequential API 를\n",
    "사용할 예정\n",
    "\n",
    "개발의 자유도는 떨어지지만 간단하게 딥러닝 모델을 만드는 도구 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd47518b",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 설계 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35577185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2751395",
   "metadata": {},
   "source": [
    "> tf.keras 를 이용해 Sequential API 를 불러 Lenet 이라는 딥러닝 네트워크를 설계한 내용이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdebe855",
   "metadata": {},
   "source": [
    "<img src=\"../Instruct_code.png\" width=\"6500px\" height=\"500px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c5daf",
   "metadata": {},
   "source": [
    "---\n",
    "우리가 만든 딥러닝 네트워크 모델을 확인해보지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9968cc53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 30,762\n",
      "Trainable params: 30,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd92e14",
   "metadata": {},
   "source": [
    "---\n",
    "근데 여기서 네트워크를 다르게 만들어 볼 수도 있는데,  \n",
    "위 에서 Conv2D  혹은 Dense , epoch 값을 변경하여 만든다.  \n",
    "(맨밑 dense 는 바꾸면 안됨 그거는 숫자 갯수인 10개로 맞춰나야 함)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33a9de0",
   "metadata": {},
   "source": [
    "---\n",
    "이 네트워크의 입력은\n",
    "\n",
    "(데이터 갯수, 이미지크기x, 이미지크기y, 채널수)\n",
    "\n",
    "의 형태를 지닌다.  \n",
    "(채널은 흑백인지 컬러인지를 의미한다.)\n",
    "\n",
    "허나 print(x_train.shape) 를 해보면  \n",
    "(60,000, 28, 28) 로 3객 나오는 것을 알 수 있다.  \n",
    "채널수를 추가해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53f0f101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Reshape - x_train_norm shape: (60000, 28, 28)\n",
      "Before Reshape - x_test_norm shape: (10000, 28, 28)\n",
      "After Reshape - x_train_reshaped shape: (60000, 28, 28, 1)\n",
      "After Reshape - x_test_reshaped shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "print(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 1)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 1)\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7637eeed",
   "metadata": {},
   "source": [
    "---\n",
    "수정된 x_train_reshaped 로 딥러닝 네트워크를 학습시켜보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a30f14c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 3ms/step - loss: 0.1956 - accuracy: 0.9401\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0637 - accuracy: 0.9807\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0465 - accuracy: 0.9859\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0355 - accuracy: 0.9890\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0294 - accuracy: 0.9904\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0239 - accuracy: 0.9928\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0197 - accuracy: 0.9936\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0171 - accuracy: 0.9947\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0131 - accuracy: 0.9955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbf7c02ec40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4bd629",
   "metadata": {},
   "source": [
    "echos=10 은  \n",
    "전체 60,000개의 데이터를 10번 반복해서 학습하라는 뜻"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ae971",
   "metadata": {},
   "source": [
    "학습이 진행됨에 따라 정확도 (accuracy) 가 올라가는 걸 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f379c4cc",
   "metadata": {},
   "source": [
    "---\n",
    "완성된 딥러닝 네트워크로 test파일을 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f890aeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0363 - accuracy: 0.9895\n",
      "test_loss: 0.03629588335752487 \n",
      "test_accuracy: 0.9894999861717224\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dfa5dc",
   "metadata": {},
   "source": [
    "와우 정확도가 98.94% 이정도면 충분한거 아니냐?  \n",
    "위에 모델에서는 evaluate 라는 함수를 썼지만\n",
    ".predict() 를 사용하면 model 이 입력값을 보고 실제로 추론한 확률분포를 출력할 수 있다.\n",
    "\n",
    "우리가 만든 딥러닝 모델이란 사실 10개의 숫자 중 어디에 가장 근접할 지에 대한 확률값을 출력하는 함수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3994cb67",
   "metadata": {},
   "source": [
    "---\n",
    "predict를 활용한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a54456c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.predict() 결과 :  [1.3132054e-14 2.6960585e-11 5.4069371e-12 1.4042201e-10 6.5124948e-14\n",
      " 1.6036312e-12 3.1894430e-17 1.0000000e+00 1.4683288e-11 1.0271363e-09]\n",
      "model이 추론한 가장 가능성이 높은 결과 :  7\n",
      "실제 데이터의 라벨 :  7\n"
     ]
    }
   ],
   "source": [
    "predicted_result = model.predict(x_test_reshaped)  # model이 추론한 확률값. \n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "idx=0  #1번째 x_test를 살펴보자. \n",
    "print('model.predict() 결과 : ', predicted_result[idx])\n",
    "print('model이 추론한 가장 가능성이 높은 결과 : ', predicted_labels[idx])\n",
    "print('실제 데이터의 라벨 : ', y_test[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2727d3",
   "metadata": {},
   "source": [
    "보면 7번째 리스트 값이 1.0000000e+00 으로 1에 가장 근접하다. 가장 그럴듯하다는 얘기다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
